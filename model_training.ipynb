{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "#explainability\n",
    "import shap\n",
    "\n",
    "#serialization\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data \n",
    "app_train = pd.read_csv(\"../raw_data/application_train.csv\").astype(\"object\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert variables that are not correctly cast as of float in the raw data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtypes_func(df):\n",
    "    #List the columns to be converted to float\n",
    "    list_columns_to_convert_to_float = (\"CNT_CHILDREN\" \n",
    "                                ,\"AMT_INCOME_TOTAL\" \n",
    "                                ,\"AMT_CREDIT\" \n",
    "                                ,\"AMT_ANNUITY\" \n",
    "                                ,\"AMT_GOODS_PRICE\" \n",
    "                                ,\"DAYS_BIRTH\"\n",
    "                                ,\"DAYS_EMPLOYED\" \n",
    "                                ,\"DAYS_REGISTRATION\" \n",
    "                                ,\"DAYS_ID_PUBLISH\"\n",
    "                                ,\"OWN_CAR_AGE\"\n",
    "                                ,\"EXT_SOURCE_1               \"\n",
    "                                ,\"EXT_SOURCE_2               \"\n",
    "                                ,\"EXT_SOURCE_3               \"\n",
    "                                ,\"APARTMENTS_AVG             \"\n",
    "                                ,\"BASEMENTAREA_AVG           \"\n",
    "                                ,\"YEARS_BEGINEXPLUATATION_AVG\"\n",
    "                                ,\"YEARS_BUILD_AVG            \"\n",
    "                                ,\"COMMONAREA_AVG             \"\n",
    "                                ,\"ELEVATORS_AVG              \"\n",
    "                                ,\"ENTRANCES_AVG              \"\n",
    "                                ,\"FLOORSMAX_AVG              \"\n",
    "                                ,\"FLOORSMIN_AVG              \"\n",
    "                                ,\"LANDAREA_AVG               \"\n",
    "                                ,\"LIVINGAPARTMENTS_AVG       \"\n",
    "                                ,\"LIVINGAREA_AVG             \"\n",
    "                                ,\"NONLIVINGAPARTMENTS_AVG    \"\n",
    "                                ,\"NONLIVINGAREA_AVG          \"\n",
    "                                ,\"APARTMENTS_MODE            \"\n",
    "                                ,\"BASEMENTAREA_MODE          \"\n",
    "                                ,\"YEARS_BEGINEXPLUATATION_MODE\"\n",
    "                                ,\"YEARS_BUILD_MODE           \"\n",
    "                                ,\"COMMONAREA_MODE            \"\n",
    "                                ,\"ELEVATORS_MODE             \"\n",
    "                                ,\"ENTRANCES_MODE             \"\n",
    "                                ,\"FLOORSMAX_MODE             \"\n",
    "                                ,\"FLOORSMIN_MODE             \"\n",
    "                                ,\"LANDAREA_MODE              \"\n",
    "                                ,\"LIVINGAPARTMENTS_MODE      \"\n",
    "                                ,\"LIVINGAREA_MODE            \"\n",
    "                                ,\"NONLIVINGAPARTMENTS_MODE   \"\n",
    "                                ,\"NONLIVINGAREA_MODE         \"\n",
    "                                ,\"APARTMENTS_MEDI            \"\n",
    "                                ,\"BASEMENTAREA_MEDI          \"\n",
    "                                ,\"YEARS_BEGINEXPLUATATION_MEDI\"\n",
    "                                ,\"YEARS_BUILD_MEDI           \"\n",
    "                                ,\"COMMONAREA_MEDI            \"\n",
    "                                ,\"ELEVATORS_MEDI             \"\n",
    "                                ,\"ENTRANCES_MEDI             \"\n",
    "                                ,\"FLOORSMAX_MEDI             \"\n",
    "                                ,\"FLOORSMIN_MEDI             \"\n",
    "                                ,\"LANDAREA_MEDI              \"\n",
    "                                ,\"LIVINGAPARTMENTS_MEDI      \"\n",
    "                                ,\"LIVINGAREA_MEDI            \"\n",
    "                                ,\"NONLIVINGAPARTMENTS_MEDI   \"\n",
    "                                ,\"NONLIVINGAREA_MEDI         \"\n",
    "                                ,\"TOTALAREA_MODE             \"\n",
    "                                ,\"OBS_30_CNT_SOCIAL_CIRCLE   \"\n",
    "                                ,\"DEF_30_CNT_SOCIAL_CIRCLE   \"\n",
    "                                ,\"OBS_60_CNT_SOCIAL_CIRCLE   \"\n",
    "                                ,\"DEF_60_CNT_SOCIAL_CIRCLE   \"\n",
    "                                ,\"DAYS_LAST_PHONE_CHANGE     \"\n",
    "                                ,\"AMT_REQ_CREDIT_BUREAU_HOUR\"\n",
    "                                ,\"AMT_REQ_CREDIT_BUREAU_DAY \"\n",
    "                                ,\"AMT_REQ_CREDIT_BUREAU_WEEK\"\n",
    "                                ,\"AMT_REQ_CREDIT_BUREAU_MON \"\n",
    "                                ,\"AMT_REQ_CREDIT_BUREAU_QRT \"\n",
    "                                ,\"AMT_REQ_CREDIT_BUREAU_YEAR\")       \n",
    "\n",
    "    #remove spaces in the list created\n",
    "    list_columns_to_convert_to_float = [s.strip() for s in list_columns_to_convert_to_float]   \n",
    "    \n",
    "    convert_count = 0\n",
    "    # convert_count_2 = 0\n",
    "\n",
    "    #convert object columns to float\n",
    "    for col in list_columns_to_convert_to_float:\n",
    "        \n",
    "        df[col] = df[col].astype(float)\n",
    "        \n",
    "        # Keep track of how many columns were label encoded\n",
    "        convert_count += 1\n",
    "\n",
    "    print('%d object columns were converted to float.' % convert_count)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 object columns were converted to float.\n"
     ]
    }
   ],
   "source": [
    "app_train = convert_dtypes_func(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(df):\n",
    "\n",
    "    # Create an anomalous flag column\n",
    "    df['DAYS_EMPLOYED_ANOM'] = df[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "    # Replace the anomalous values with nan\n",
    "    df['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "    #correct sign of Days Birth\n",
    "    df[\"DAYS_BIRTH\"] = abs(df[\"DAYS_BIRTH\"])\n",
    "    df['AGE_INT'] = (df['DAYS_BIRTH'] / 365).astype(float)\n",
    "\n",
    "    #footing financial ratios\n",
    "    df['annuity_income_ratio'] = df['AMT_INCOME_TOTAL'] / df['AMT_ANNUITY'] \n",
    "    df['credit_annuity_ratio'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "    df['credit_goods_price_ratio'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    df['credit_downpayment'] = df['AMT_GOODS_PRICE'] - df['AMT_CREDIT']\n",
    " \n",
    "    print('Feature engineering success')\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering success\n"
     ]
    }
   ],
   "source": [
    "app_train = feature_eng(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_feature_selection(df):\n",
    "    columns_list = df.columns.to_list()\n",
    "\n",
    "    columns_to_drop_intersec = (['DAYS_BIRTH',\n",
    "    'REGION_RATING_CLIENT_W_CITY',\n",
    "    'BASEMENTAREA_MODE',\n",
    "    'YEARS_BUILD_MODE',\n",
    "    'COMMONAREA_MODE',\n",
    "    'ELEVATORS_MODE',\n",
    "    'ENTRANCES_MODE',\n",
    "    'FLOORSMAX_MODE',\n",
    "    'LANDAREA_MODE',\n",
    "    'LIVINGAPARTMENTS_MODE',\n",
    "    'NONLIVINGAPARTMENTS_MODE',\n",
    "    'NONLIVINGAREA_MODE',\n",
    "    'APARTMENTS_MEDI',\n",
    "    'BASEMENTAREA_MEDI',\n",
    "    'YEARS_BEGINEXPLUATATION_MEDI',\n",
    "    'YEARS_BUILD_MEDI',\n",
    "    'COMMONAREA_MEDI',\n",
    "    'ELEVATORS_MEDI',\n",
    "    'ENTRANCES_MEDI',\n",
    "    'FLOORSMAX_MEDI',\n",
    "    'FLOORSMIN_MEDI',\n",
    "    'LIVINGAPARTMENTS_MEDI',\n",
    "    'LIVINGAREA_MEDI',\n",
    "    'NONLIVINGAPARTMENTS_MEDI',\n",
    "    'NONLIVINGAREA_MEDI',\n",
    "    'OBS_60_CNT_SOCIAL_CIRCLE'])\n",
    "\n",
    "    #Drop columns\n",
    "    df_selec_col = pd.DataFrame(data=df, columns=columns_list).drop(columns_to_drop_intersec, axis=1)\n",
    "    \n",
    "    print('Feature selection success')\n",
    "\n",
    "    return df_selec_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection success\n"
     ]
    }
   ],
   "source": [
    "app_train = df_feature_selection(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding - Standardization - Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep id into a separate serie\n",
    "user_id = app_train[['SK_ID_CURR']]\n",
    "\n",
    "#create list of features by type\n",
    "cat_features = app_train.select_dtypes(include=['object']).drop(['SK_ID_CURR','TARGET'], axis=1)\n",
    "num_features = app_train.select_dtypes(exclude=['object'])\n",
    "\n",
    "#One hot encoding categorical variables\n",
    "ohe = OneHotEncoder()\n",
    "cat_array = ohe.fit_transform(cat_features).todense()\n",
    "cat_array = np.asarray(cat_array)\n",
    "\n",
    "#Mean Imputation of missing values\n",
    "imp_mean = SimpleImputer()\n",
    "num_array = num_features.to_numpy()\n",
    "num_array = imp_mean.fit_transform(num_array)\n",
    "\n",
    "#Standard Scaling numerical variables\n",
    "scaler = StandardScaler()\n",
    "num_array = scaler.fit_transform(num_array)\n",
    "\n",
    "#concatenate\n",
    "X = np.concatenate([cat_array, num_array], axis=1)\n",
    "y = app_train['TARGET'].astype(float)\n",
    "\n",
    "#dataframe\n",
    "df_train = pd.concat([user_id, cat_features, num_features], axis=1)\n",
    "df_train = df_train.astype('object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with best params\n",
    "model = LogisticRegression(class_weight = 'balanced', C=0.005, max_iter=1000)\n",
    "\n",
    "#fit\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bin/model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ohe, 'bin/ohe.joblib') #into a folder bin (for binary)\n",
    "joblib.dump(imp_mean, 'bin/imp_mean.joblib')\n",
    "joblib.dump(scaler, 'bin/scaler.joblib')\n",
    "joblib.dump(model, 'bin/model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export pre-processed dataset to be used for Dashboard Streamlit (on which heroku deployed model will predicting scoring) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 object columns were converted to float.\n",
      "Feature engineering success\n",
      "Feature selection success\n",
      "df_test exported to dashboard_data folder.\n"
     ]
    }
   ],
   "source": [
    "app_test = pd.read_csv(\"../raw_data/application_test.csv\").astype(\"object\")\n",
    "\n",
    "app_test_converted = convert_dtypes_func(app_test)\n",
    "app_test_eng = feature_eng(app_test)\n",
    "app_test_selec_col = df_feature_selection(app_test_eng)\n",
    "\n",
    "df_test = app_test_selec_col.sample(frac=0.05, random_state=0)\n",
    "df_test = df_test.astype('object')\n",
    "\n",
    "df_test.to_csv(\"./dashboard_data/df_test.csv\", index=False)\n",
    "\n",
    "print('df_test exported to dashboard_data folder.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, create_model, Field, ValidationError\n",
    "\n",
    "model = {}\n",
    "for i in range(len(df_train.dtypes)):\n",
    "    name = df_train.dtypes.index[i]\n",
    "    var_type = type(df_train.iloc[0, i])\n",
    "    model.update({name: (var_type, Field(...))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bin/data_dict.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = joblib.dump(model, 'bin/data_dict.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_pandas_profiling = [\"CODE_GENDER\",\n",
    "                             \"AGE_INT\", \n",
    "                             \"NAME_TYPE_SUITE\",\n",
    "                             \"NAME_EDUCATION_TYPE\",\n",
    "                             \"NAME_INCOME_TYPE\",\n",
    "                             \"ORGANIZATION_TYPE\",\n",
    "                             \"OCCUPATION_TYPE\",\n",
    "                             \"NAME_HOUSING_TYPE\",\n",
    "                             \"CNT_CHILDREN\", \n",
    "                             \"AMT_INCOME_TOTAL\", \n",
    "                             \"AMT_GOODS_PRICE\"                             \n",
    "                             ]\n",
    "\n",
    "colonnes_scoring_predicted = [\"CODE_GENDER\",\n",
    "                              \"NAME_EDUCATION_TYPE\",\n",
    "                              \"DAYS_EMPLOYED\"\n",
    "                              \"EXT_SOURCE_1\",\n",
    "                              \"EXT_SOURCE_2\",\n",
    "                              \"EXT_SOURCE_3\",\n",
    "                              \"credit_downpayment\",\n",
    "                              \"AMT_INCOME_TOTAL\",\n",
    "                              \"annuity_income_ratio\",\n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OWN_CAR_AGE', 'AGE_INT']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste = [i for i in df_test.columns.to_list()]\n",
    "matching = [s for s in liste if \"AGE\" in s]\n",
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1613, 824]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_value = df_test['CODE_GENDER'].value_counts().tolist()\n",
    "liste_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'YEARS_BIRTH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'YEARS_BIRTH'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/guilhemberthou/dev/P7_Scoring/model_training.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guilhemberthou/dev/P7_Scoring/model_training.ipynb#ch0000045?line=0'>1</a>\u001b[0m df_test[\u001b[39m'\u001b[39;49m\u001b[39mYEARS_BIRTH\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'YEARS_BIRTH'"
     ]
    }
   ],
   "source": [
    "df_test['YEARS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
